{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout, concatenate\n",
    "from keras.layers import Concatenate,Conv2D,BatchNormalization,MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import  SequentialMemory\n",
    "from rl.processors import Processor\n",
    "from rl.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        p.connect(p.GUI)\n",
    "        p.setRealTimeSimulation(1)\n",
    "        p.resetDebugVisualizerCamera(cameraDistance=10, cameraYaw=0, cameraPitch=-40, cameraTargetPosition=[0.55,-0.35,0.2])\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'sensor' : spaces.Box(np.array([-1000]*10), np.array([1000]*10)),\n",
    "            'image'  : spaces.Box(low=0, high=1, shape=(64, 64))\n",
    "        }) \n",
    "        \n",
    "        self.timestep = 1./240.\n",
    "        self.stp = 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        #print(\"i=%d\" % self.stp)\n",
    "        self.stp+=1\n",
    "        #print(\"time = \" , time.time()-self.time)\n",
    "     \n",
    "        if (action == 0):\n",
    "            self.speed = self.speed + 1\n",
    "        if (action == 1):\n",
    "            self.speed = self.speed - 1 \n",
    "        if (action == 2):\n",
    "            self.speed = self.speed  \n",
    "        if (action == 3):\n",
    "            self.steer = self.steer - 1 \n",
    "        if (action == 4):\n",
    "            self.steer = self.steer + 1\n",
    "        if (action == 5):\n",
    "            self.steer = self.steer \n",
    "            \n",
    "              \n",
    "        self.applyAction([self.speed,self.steer])\n",
    "\n",
    "        #p.setRealTimeSimulation(1)\n",
    "        time.sleep(0.5)\n",
    "        #p.setRealTimeSimulation(0)\n",
    "        \n",
    "        state = p.getLinkState(self.pid,0)[0]\n",
    "        if state[2] <= 0.5 or  state[2] >= 2 or abs(self.speed)>2 or abs(self.steer)>4:\n",
    "            reward = -100\n",
    "            done = True\n",
    "        else :\n",
    "            #reward = math.sqrt((self.origin[0]-state[0])**2+(self.origin[1]-state[1])**2)\n",
    "            reward = state[0] - self.origin[0]\n",
    "            #reward = 1\n",
    "            done = False\n",
    "        self.origin = state \n",
    "        \n",
    "        velocity = p.getBaseVelocity(self.pid)\n",
    "        img = self.getImage()\n",
    "        observation = {'sensor':list(self.getObservation()) + list(velocity[0])+list(velocity[1]),\n",
    "                       'image': img}\n",
    "        \n",
    "        info = {'x':'','y':'','z':''}\n",
    "        #print(\"Step: \",self.stp)\n",
    "        #xx = time.time()\n",
    "        #print(\"Time: \",xx-self.tttt)\n",
    "        #self.tttt = xx\n",
    "        #print(\"Action: \",action)\n",
    "        #print(\"Reward: \",reward)\n",
    "        #self.stp +=1\n",
    "        return observation, reward, done, info\n",
    "            \n",
    "    def applyAction(self, motorCommands):\n",
    "        targetVelocity = motorCommands[0] * self.speedMultiplier\n",
    "        #print(\"targetVelocity\")\n",
    "        #print(targetVelocity)\n",
    "        steeringAngle = motorCommands[1] * self.steeringMultiplier\n",
    "        #print(\"steeringAngle\")\n",
    "        #print(steeringAngle)\n",
    "\n",
    "\n",
    "        for motor in self.motorizedwheels:\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    motor,\n",
    "                                    p.VELOCITY_CONTROL,\n",
    "                                    targetVelocity=targetVelocity,\n",
    "                                    force=self.maxForce)\n",
    "        for steer in self.steeringLinks:\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    steer,\n",
    "                                    p.POSITION_CONTROL,\n",
    "                                    targetPosition=steeringAngle)\n",
    "\n",
    "    def reset(self):\n",
    "        #print(\"Reset\")\n",
    "        #print(\"setp:\",self.stp)\n",
    "        self.stp = 0\n",
    "\n",
    "        p.resetSimulation()\n",
    "\n",
    "        urdfRootPath = pybullet_data.getDataPath()\n",
    "        planeUid = p.loadURDF(os.path.join(urdfRootPath,\"plane.urdf\"), basePosition=[0,0,0])\n",
    "        \n",
    "        \n",
    "        for i in range(np.random.randint(1,10)):\n",
    "            p.loadURDF(os.path.join(urdfRootPath, \"sphere2.urdf\"),basePosition=[\n",
    "                np.random.randint(5,15),\n",
    "                np.random.randint(-2,2),\n",
    "               0.5\n",
    "           ])\n",
    "     \n",
    "        self.pid = p.loadURDF(os.path.join(urdfRootPath, \"bicycle/bike.urdf\"),basePosition=[0,0,1])     \n",
    "           \n",
    "        \n",
    "        self.origin = p.getLinkState(self.pid,0)[0]\n",
    "        p.setGravity(0,0,-10)\n",
    "        for wheel in range(p.getNumJoints(self.pid)):\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    wheel,\n",
    "                                    p.VELOCITY_CONTROL,\n",
    "                                    targetVelocity=0,\n",
    "                                    force=0)\n",
    "\n",
    "        self.steeringLinks = [0]\n",
    "        self.maxForce = 20\n",
    "        self.nMotors = 2\n",
    "        self.motorizedwheels = [1, 2]\n",
    "        self.speedMultiplier = 10.\n",
    "        self.steeringMultiplier = 0.5\n",
    "        \n",
    "        self.speed = 0 \n",
    "        self.steer = 0\n",
    "\n",
    "        velocity = p.getBaseVelocity(self.pid)\n",
    "        img = self.getImage()\n",
    "        observation = {'sensor': list(self.getObservation()) + list(velocity[0])+list(velocity[1]),\n",
    "                       'image': img}\n",
    "        \n",
    "\n",
    "        p.configureDebugVisualizer(p.COV_ENABLE_RENDERING,1)\n",
    "        \n",
    "        return observation\n",
    "        \n",
    "    \n",
    "    def getImage(self):\n",
    "        img = env.render()\n",
    "        img = cv2.resize(img, (64,64), interpolation = cv2.INTER_NEAREST )\n",
    "        img = img[:,:,2]\n",
    "        img =img.reshape((64,64))\n",
    "        img = np.asarray(img, dtype='float32')\n",
    "        img /= 255.0\n",
    "        return img\n",
    "        \n",
    "    def getObservationDimension(self):\n",
    "        return len(self.getObservation())\n",
    "    \n",
    "    def getObservation(self):\n",
    "        observation = []\n",
    "        pos, orn = p.getBasePositionAndOrientation(self.pid)\n",
    "\n",
    "        #observation.extend(list(pos))\n",
    "        observation.extend(list(orn))\n",
    "        return observation\n",
    "        \n",
    "    def render(self, mode='rgb_array'):\n",
    "        pos, orn = p.getBasePositionAndOrientation(self.pid)\n",
    "      \n",
    "        view_matrix = p.computeViewMatrixFromYawPitchRoll(cameraTargetPosition=[pos[0]+11.3,pos[1],pos[2]],\n",
    "                                                            distance=10,\n",
    "                                                            yaw=-90 ,\n",
    "                                                            pitch=0,\n",
    "                                                            roll=0,\n",
    "                                                            upAxisIndex=2)\n",
    "        proj_matrix = p.computeProjectionMatrixFOV(fov=60,\n",
    "                                                     aspect=float(960) /720,\n",
    "                                                     nearVal=0.1,\n",
    "                                                     farVal=100.0)\n",
    "        (_, _, px, _, _) = p.getCameraImage(width=64,\n",
    "                                              height=64,\n",
    "                                              viewMatrix=view_matrix,\n",
    "                                              projectionMatrix=proj_matrix,\n",
    "                                              renderer=p.ER_BULLET_HARDWARE_OPENGL)\n",
    "\n",
    "        rgb_array = np.array(px, dtype=np.uint8)\n",
    "        rgb_array = np.reshape(rgb_array, (64,64, 4))\n",
    "\n",
    "        rgb_array = rgb_array[:, :, :3]\n",
    "        return rgb_array\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = BikeEnv()\n",
    "np.random.seed(123)\n",
    "env.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp():\n",
    "    inputs = Input(shape=env.observation_space['sensor'].shape)\n",
    "    x = Dense(16, activation='relu')(inputs)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    #x = Dense(8,  activation='relu')(x)\n",
    "    x = Dense(nb_actions, activation='linear')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    inputShape = (64, 64,1)\n",
    "    inputs = Input(shape=inputShape,name='image')\n",
    "    x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(8)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(6)(x)\n",
    "    x = Activation(\"linear\")(x)\n",
    " \n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   160         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 64)   256         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 128)    73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 128)    512         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           65568       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32)           128         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           528         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16)           64          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            136         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           176         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8)            32          activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           272         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8)            0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           272         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 6)            54          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            102         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 6)            0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           dense_4[0][0]                    \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            104         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 6)            54          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 165,602\n",
      "Trainable params: 165,010\n",
      "Non-trainable params: 592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp = create_mlp()\n",
    "cnn = create_cnn()\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "x = Dense(8, activation=\"relu\")(combinedInput)\n",
    "x = Dense(nb_actions, activation=\"relu\")(x)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCalback(Callback ):\n",
    "    def on_action_begin(self, action, logs={}):\n",
    "        p.setRealTimeSimulation(1)\n",
    "\n",
    "    def on_action_end(self, action, logs={}):\n",
    "        p.setRealTimeSimulation(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessor(Processor):\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        batch = np.squeeze(batch, axis=1)\n",
    "        b_shape = batch.shape[0]\n",
    "        sensor = [batch[i][0] for i in range(b_shape)]\n",
    "        images = [batch[i][1] for i in range(b_shape)]\n",
    "        #return [sensor,images]\n",
    "\n",
    "        return batch\n",
    "    def process_observation(self, observation):\n",
    "        \n",
    "        #observation = observation['sensor'],observation['image'].reshape((64,64,1))\n",
    "        observation = observation['sensor'] \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=create_mlp(), nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.processor = CustomProcessor()\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 250000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "   11/10000 [..............................] - ETA: 1:54:16 - reward: -27.3079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\rl\\memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7811s 781ms/step - reward: -29.8715\n",
      "3030 episodes - episode_reward: -98.587 [-107.143, -93.421] - loss: 34.242 - mae: 80.054 - mean_q: -93.493\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 7559s 756ms/step - reward: -29.7797\n",
      "3033 episodes - episode_reward: -98.185 [-106.280, -93.102] - loss: 0.855 - mae: 81.822 - mean_q: -96.241\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 7498s 750ms/step - reward: -29.9241\n",
      "3054 episodes - episode_reward: -97.983 [-107.188, -92.903] - loss: 0.588 - mae: 81.847 - mean_q: -96.226\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 7621s 762ms/step - reward: -28.4265\n",
      "2913 episodes - episode_reward: -97.585 [-105.591, -92.892] - loss: 0.478 - mae: 81.863 - mean_q: -96.040\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 7504s 750ms/step - reward: -27.2960\n",
      "2807 episodes - episode_reward: -97.243 [-105.184, -93.977] - loss: 0.387 - mae: 81.842 - mean_q: -95.830\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 7414s 741ms/step - reward: -26.0440\n",
      "2685 episodes - episode_reward: -96.997 [-106.128, -91.119] - loss: 0.326 - mae: 81.905 - mean_q: -95.726\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 7422s 742ms/step - reward: -26.0908\n",
      "2690 episodes - episode_reward: -96.992 [-105.424, -92.717] - loss: 0.312 - mae: 81.960 - mean_q: -95.776\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 7440s 744ms/step - reward: -26.2537\n",
      "2707 episodes - episode_reward: -96.986 [-105.921, -92.841] - loss: 0.293 - mae: 82.007 - mean_q: -95.821\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 7463s 746ms/step - reward: -26.4590\n",
      "2726 episodes - episode_reward: -97.061 [-106.099, -93.113] - loss: 0.296 - mae: 82.012 - mean_q: -95.825\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 7436s 744ms/step - reward: -26.3901\n",
      "2719 episodes - episode_reward: -97.057 [-107.880, -92.835] - loss: 0.300 - mae: 82.012 - mean_q: -95.851\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      "10000/10000 [==============================] - 7449s 745ms/step - reward: -26.4828\n",
      "2728 episodes - episode_reward: -97.078 [-106.871, -92.980] - loss: 0.298 - mae: 82.014 - mean_q: -95.853\n",
      "\n",
      "Interval 12 (110000 steps performed)\n",
      "10000/10000 [==============================] - 7441s 744ms/step - reward: -26.3724\n",
      "2718 episodes - episode_reward: -97.029 [-105.256, -92.797] - loss: 0.293 - mae: 82.020 - mean_q: -95.851\n",
      "\n",
      "Interval 13 (120000 steps performed)\n",
      "10000/10000 [==============================] - 7410s 741ms/step - reward: -26.0412\n",
      "2686 episodes - episode_reward: -96.952 [-103.763, -91.346] - loss: 0.290 - mae: 82.023 - mean_q: -95.854\n",
      "\n",
      "Interval 14 (130000 steps performed)\n",
      "10000/10000 [==============================] - 7442s 744ms/step - reward: -26.3917\n",
      "2719 episodes - episode_reward: -97.065 [-109.073, -92.857] - loss: 0.279 - mae: 82.011 - mean_q: -95.865\n",
      "\n",
      "Interval 15 (140000 steps performed)\n",
      "10000/10000 [==============================] - 7415s 742ms/step - reward: -25.7950\n",
      "2661 episodes - episode_reward: -96.936 [-105.474, -92.740] - loss: 0.278 - mae: 82.031 - mean_q: -95.873\n",
      "\n",
      "Interval 16 (150000 steps performed)\n",
      "10000/10000 [==============================] - 6990s 699ms/step - reward: -24.5098\n",
      "2533 episodes - episode_reward: -96.762 [-105.138, -92.474] - loss: 0.316 - mae: 82.018 - mean_q: -95.750\n",
      "\n",
      "Interval 17 (160000 steps performed)\n",
      "10000/10000 [==============================] - 6935s 694ms/step - reward: -23.7118\n",
      "2457 episodes - episode_reward: -96.507 [-109.211, -92.790] - loss: 0.362 - mae: 82.044 - mean_q: -95.567\n",
      "\n",
      "Interval 18 (170000 steps performed)\n",
      "10000/10000 [==============================] - 6942s 694ms/step - reward: -23.6492\n",
      "2453 episodes - episode_reward: -96.409 [-107.037, -92.916] - loss: 0.388 - mae: 82.080 - mean_q: -95.386\n",
      "\n",
      "Interval 19 (180000 steps performed)\n",
      "10000/10000 [==============================] - 7038s 704ms/step - reward: -24.5069\n",
      "2538 episodes - episode_reward: -96.560 [-105.300, -93.086] - loss: 0.379 - mae: 82.110 - mean_q: -95.356\n",
      "\n",
      "Interval 20 (190000 steps performed)\n",
      "10000/10000 [==============================] - 7045s 705ms/step - reward: -24.9444\n",
      "2581 episodes - episode_reward: -96.648 [-110.200, -92.802] - loss: 0.367 - mae: 82.134 - mean_q: -95.480\n",
      "\n",
      "Interval 21 (200000 steps performed)\n",
      "10000/10000 [==============================] - 7039s 704ms/step - reward: -25.2327\n",
      "2608 episodes - episode_reward: -96.750 [-105.735, -92.205] - loss: 0.342 - mae: 82.145 - mean_q: -95.619\n",
      "\n",
      "Interval 22 (210000 steps performed)\n",
      "10000/10000 [==============================] - 7087s 709ms/step - reward: -25.3303\n",
      "2617 episodes - episode_reward: -96.792 [-104.760, -92.143] - loss: 0.317 - mae: 82.151 - mean_q: -95.757\n",
      "\n",
      "Interval 23 (220000 steps performed)\n",
      "10000/10000 [==============================] - 7068s 707ms/step - reward: -25.6320\n",
      "2646 episodes - episode_reward: -96.871 [-104.676, -92.964] - loss: 0.311 - mae: 82.094 - mean_q: -95.782\n",
      "\n",
      "Interval 24 (230000 steps performed)\n",
      "10000/10000 [==============================] - 7098s 710ms/step - reward: -25.8148\n",
      "2663 episodes - episode_reward: -96.940 [-105.227, -88.237] - loss: 0.316 - mae: 82.066 - mean_q: -95.775\n",
      "\n",
      "Interval 25 (240000 steps performed)\n",
      " 1940/10000 [====>.........................] - ETA: 1:38:39 - reward: -25.6780done, took 176986.991 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14cda2e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=250000, visualize=False, verbose=1,callbacks  = [CustomCalback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
