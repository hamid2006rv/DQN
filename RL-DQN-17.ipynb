{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout, concatenate\n",
    "from keras.layers import Concatenate,Conv2D,BatchNormalization,MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import  SequentialMemory\n",
    "from rl.processors import Processor\n",
    "from rl.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        p.connect(p.GUI)\n",
    "        p.setRealTimeSimulation(1)\n",
    "        p.resetDebugVisualizerCamera(cameraDistance=10, cameraYaw=0, cameraPitch=-40, cameraTargetPosition=[0.55,-0.35,0.2])\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(np.array([-1000]*74), np.array([1000]*74)) \n",
    "        \n",
    "        self.timestep = 1./240.\n",
    "        self.stp = 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        #print(\"i=%d\" % self.stp)\n",
    "        self.stp+=1\n",
    "        #print(\"time = \" , time.time()-self.time)\n",
    "     \n",
    "        if (action == 0):\n",
    "            self.speed = self.speed + 1\n",
    "        if (action == 1):\n",
    "            self.speed = self.speed - 1 \n",
    "        if (action == 2):\n",
    "            self.speed = self.speed  \n",
    "        if (action == 3):\n",
    "            self.steer = self.steer - 1 \n",
    "        if (action == 4):\n",
    "            self.steer = self.steer + 1\n",
    "        if (action == 5):\n",
    "            self.steer = self.steer \n",
    "            \n",
    "              \n",
    "        self.applyAction([self.speed,self.steer])\n",
    "\n",
    "        #p.setRealTimeSimulation(1)\n",
    "        time.sleep(0.2)\n",
    "        #p.setRealTimeSimulation(0)\n",
    "        \n",
    "        state = p.getLinkState(self.pid,0)[0]\n",
    "        if state[2] <= 0.5 or  state[2] >= 2 or abs(self.speed)>2 or abs(self.steer)>4:\n",
    "            reward = -100\n",
    "            done = True\n",
    "        else :\n",
    "            #reward = math.sqrt((self.origin[0]-state[0])**2+(self.origin[1]-state[1])**2)\n",
    "            reward = state[0] - self.origin[0]\n",
    "            #reward = np.sign(state[0] - self.origin[0])*1\n",
    "            #reward = 1\n",
    "            done = False\n",
    "        self.origin = state \n",
    "        \n",
    "        velocity = p.getBaseVelocity(self.pid)\n",
    "        blobs = self.getBlobs()\n",
    "        observation = list(self.getObservation()) + list(velocity[0])+list(velocity[1]) + blobs\n",
    "                      \n",
    "        \n",
    "        info = {'x':'','y':'','z':''}\n",
    "        #print(\"Step: \",self.stp)\n",
    "        #xx = time.time()\n",
    "        #print(\"Time: \",xx-self.tttt)\n",
    "        #self.tttt = xx\n",
    "        #print(\"Action: \",action)\n",
    "        #print(\"Reward: \",reward)\n",
    "        #self.stp +=1\n",
    "        return observation, reward, done, info\n",
    "            \n",
    "    def applyAction(self, motorCommands):\n",
    "        targetVelocity = motorCommands[0] * self.speedMultiplier\n",
    "        #print(\"targetVelocity\")\n",
    "        #print(targetVelocity)\n",
    "        steeringAngle = motorCommands[1] * self.steeringMultiplier\n",
    "        #print(\"steeringAngle\")\n",
    "        #print(steeringAngle)\n",
    "\n",
    "\n",
    "        for motor in self.motorizedwheels:\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    motor,\n",
    "                                    p.VELOCITY_CONTROL,\n",
    "                                    targetVelocity=targetVelocity,\n",
    "                                    force=self.maxForce)\n",
    "        for steer in self.steeringLinks:\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    steer,\n",
    "                                    p.POSITION_CONTROL,\n",
    "                                    targetPosition=steeringAngle)\n",
    "\n",
    "    def reset(self):\n",
    "        #print(\"Reset\")\n",
    "        #print(\"setp:\",self.stp)\n",
    "        self.stp = 0\n",
    "\n",
    "        p.resetSimulation()\n",
    "\n",
    "        urdfRootPath = pybullet_data.getDataPath()\n",
    "        planeUid = p.loadURDF(os.path.join(urdfRootPath,\"plane.urdf\"), basePosition=[0,0,0])\n",
    "        \n",
    "        \n",
    "        for i in range(np.random.randint(0,20)):\n",
    "            p.loadURDF(os.path.join(urdfRootPath, \"sphere2.urdf\"),basePosition=[\n",
    "                np.random.randint(5,20),\n",
    "                np.random.randint(-10,10),\n",
    "               0.5\n",
    "           ])\n",
    "     \n",
    "        self.pid = p.loadURDF(os.path.join(urdfRootPath, \"bicycle/bike.urdf\"),basePosition=[0,0,1])     \n",
    "           \n",
    "        \n",
    "        self.origin = p.getLinkState(self.pid,0)[0]\n",
    "        p.setGravity(0,0,-10)\n",
    "        for wheel in range(p.getNumJoints(self.pid)):\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    wheel,\n",
    "                                    p.VELOCITY_CONTROL,\n",
    "                                    targetVelocity=0,\n",
    "                                    force=0)\n",
    "\n",
    "        self.steeringLinks = [0]\n",
    "        self.maxForce = 20\n",
    "        self.nMotors = 2\n",
    "        self.motorizedwheels = [1, 2]\n",
    "        self.speedMultiplier = 10.\n",
    "        self.steeringMultiplier = 0.5\n",
    "        \n",
    "        self.speed = 0 \n",
    "        self.steer = 0\n",
    "\n",
    "        velocity = p.getBaseVelocity(self.pid)\n",
    "        blobs = self.getBlobs()\n",
    "        observation = list(self.getObservation()) + list(velocity[0])+list(velocity[1]) + blobs\n",
    "        \n",
    "\n",
    "        p.configureDebugVisualizer(p.COV_ENABLE_RENDERING,1)\n",
    "        \n",
    "        return observation\n",
    "        \n",
    "    \n",
    "    def getBlobs(self):\n",
    "        blobs = env.render()\n",
    "       \n",
    "        blobs_list = [0]*64 \n",
    "        for b in blobs:\n",
    "            x , y , r = b\n",
    "            r = int(min(1,r))\n",
    "            x = int(x)\n",
    "            for i in range(-r,r):\n",
    "                if x+i >= 0 and x+i<64:\n",
    "                    blobs_list[x+i] = 1\n",
    "        return blobs_list\n",
    "        \n",
    "    def getObservationDimension(self):\n",
    "        return len(self.getObservation())\n",
    "    \n",
    "    def getObservation(self):\n",
    "        observation = []\n",
    "        pos, orn = p.getBasePositionAndOrientation(self.pid)\n",
    "\n",
    "        #observation.extend(list(pos))\n",
    "        observation.extend(list(orn))\n",
    "        return observation\n",
    "        \n",
    "    def render(self, mode='rgb_array'):\n",
    "        pos, orn = p.getBasePositionAndOrientation(self.pid)\n",
    "      \n",
    "        view_matrix = p.computeViewMatrixFromYawPitchRoll(cameraTargetPosition=[pos[0]+11.3,pos[1],pos[2]],\n",
    "                                                            distance=10,\n",
    "                                                            yaw=-90 ,\n",
    "                                                            pitch=0,\n",
    "                                                            roll=0,\n",
    "                                                            upAxisIndex=2)\n",
    "        proj_matrix = p.computeProjectionMatrixFOV(fov=60,\n",
    "                                                     aspect=float(960) /720,\n",
    "                                                     nearVal=0.1,\n",
    "                                                     farVal=100.0)\n",
    "        (_, _, px, _, s) = p.getCameraImage(width=64,\n",
    "                                              height=64,\n",
    "                                              viewMatrix=view_matrix,\n",
    "                                              projectionMatrix=proj_matrix,\n",
    "                                              renderer=p.ER_BULLET_HARDWARE_OPENGL)\n",
    "\n",
    "        #rgb_array = np.array(px, dtype=np.uint8)\n",
    "        #rgb_array = np.reshape(rgb_array, (64,64, 4))\n",
    "\n",
    "        #rgb_array = rgb_array[:, :, :3]\n",
    "        \n",
    "        #return rgb_array\n",
    "        for i in range(64):\n",
    "            for j in range(64):\n",
    "                if s[i,j] <= 0 :\n",
    "                    s[i,j] = 0\n",
    "                else:\n",
    "                    s[i,j] = 1\n",
    "        image = s \n",
    "        image = np.zeros((64,64))\n",
    "        for i in range(64):\n",
    "            for j in range(64):\n",
    "                if s[i,j] > 0 : image[i,j]=1\n",
    "\n",
    "        blobs_doh = blob_doh(image, max_sigma=30, threshold=.01)\n",
    "\n",
    "          \n",
    "        return blobs_doh\n",
    "    \n",
    "    def close(self):\n",
    "        p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = BikeEnv()\n",
    "np.random.seed(123)\n",
    "env.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 74)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1200      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 2,118\n",
      "Trainable params: 2,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=env.observation_space.shape)\n",
    "x = Dense(16, activation='relu')(inputs)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(16,  activation='relu')(x)\n",
    "x = Dense(nb_actions, activation='linear')(x)\n",
    "model = Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCalback(Callback ):\n",
    "    def on_action_begin(self, action, logs={}):\n",
    "        #p.setRealTimeSimulation(1)\n",
    "        pass\n",
    "\n",
    "    def on_action_end(self, action, logs={}):\n",
    "        #p.setRealTimeSimulation(0)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessor(Processor):\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        batch = np.squeeze(batch, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=100,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.processor = CustomProcessor()\n",
    "dqn.compile(Adam(lr=1e-5), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('d:\\\\RL-DQN-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 250000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "    5/10000 [..............................] - ETA: 43:08 - reward: -19.8366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\skimage\\feature\\blob.py:125: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r1 = blob1[-1] / blob2[-1]\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\skimage\\feature\\blob.py:126: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pos1 = blob1[:ndim] / (max_sigma * root_ndim)\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\skimage\\feature\\blob.py:127: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pos2 = blob2[:ndim] / (max_sigma * root_ndim)\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\skimage\\feature\\blob.py:129: RuntimeWarning: invalid value encountered in subtract\n",
      "  d = np.sqrt(np.sum((pos2 - pos1)**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15/10000 [..............................] - ETA: 59:21 - reward: -13.1085  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\skimage\\feature\\blob.py:126: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos1 = blob1[:ndim] / (max_sigma * root_ndim)\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\skimage\\feature\\blob.py:127: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos2 = blob2[:ndim] / (max_sigma * root_ndim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4545s 454ms/step - reward: -15.7435\n",
      "1587 episodes - episode_reward: -99.203 [-109.653, -90.659] - loss: 2.805 - mae: 79.911 - mean_q: -95.061\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 4399s 440ms/step - reward: -15.7278\n",
      "1583 episodes - episode_reward: -99.354 [-106.398, -89.623] - loss: 2.147 - mae: 79.901 - mean_q: -95.175\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 4483s 448ms/step - reward: -16.0731\n",
      "1617 episodes - episode_reward: -99.401 [-108.734, -91.885] - loss: 1.973 - mae: 79.909 - mean_q: -95.214\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 4062s 406ms/step - reward: -15.4639\n",
      "1556 episodes - episode_reward: -99.382 [-105.460, -91.306] - loss: 1.797 - mae: 79.941 - mean_q: -95.289\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 4048s 405ms/step - reward: -15.4904\n",
      "1559 episodes - episode_reward: -99.362 [-107.540, -89.659] - loss: 1.632 - mae: 79.934 - mean_q: -95.308\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 4071s 407ms/step - reward: -15.5181\n",
      "1561 episodes - episode_reward: -99.411 [-106.089, -89.526] - loss: 1.441 - mae: 79.965 - mean_q: -95.360\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 4069s 407ms/step - reward: -15.6704\n",
      "1576 episodes - episode_reward: -99.432 [-106.980, -87.907] - loss: 1.254 - mae: 79.989 - mean_q: -95.421\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 4075s 408ms/step - reward: -15.5621\n",
      "1565 episodes - episode_reward: -99.441 [-105.507, -90.669] - loss: 1.167 - mae: 79.960 - mean_q: -95.395\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 4046s 405ms/step - reward: -15.6538\n",
      "1575 episodes - episode_reward: -99.387 [-106.595, -86.469] - loss: 1.060 - mae: 79.985 - mean_q: -95.430\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 4081s 408ms/step - reward: -15.5236\n",
      "1562 episodes - episode_reward: -99.383 [-106.381, -90.301] - loss: 1.054 - mae: 79.990 - mean_q: -95.436\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      "10000/10000 [==============================] - 4059s 406ms/step - reward: -15.5976\n",
      "1569 episodes - episode_reward: -99.411 [-106.048, -90.048] - loss: 1.084 - mae: 79.963 - mean_q: -95.389\n",
      "\n",
      "Interval 12 (110000 steps performed)\n",
      "10000/10000 [==============================] - 4090s 409ms/step - reward: -15.7627\n",
      "1585 episodes - episode_reward: -99.449 [-107.315, -93.646] - loss: 1.059 - mae: 79.975 - mean_q: -95.412\n",
      "\n",
      "Interval 13 (120000 steps performed)\n",
      "10000/10000 [==============================] - 4048s 405ms/step - reward: -15.4820\n",
      "1558 episodes - episode_reward: -99.371 [-107.402, -92.098] - loss: 1.088 - mae: 79.986 - mean_q: -95.428\n",
      "\n",
      "Interval 14 (130000 steps performed)\n",
      "10000/10000 [==============================] - 4047s 405ms/step - reward: -15.4294\n",
      "1552 episodes - episode_reward: -99.416 [-106.403, -90.186] - loss: 1.086 - mae: 79.966 - mean_q: -95.399\n",
      "\n",
      "Interval 15 (140000 steps performed)\n",
      " 9577/10000 [===========================>..] - ETA: 2:50 - reward: -15.4239done, took 61974.426 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18e79dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=250000, visualize=False, verbose=1,callbacks  = [CustomCalback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] d:\\RL-DQN-17 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True!\n"
     ]
    }
   ],
   "source": [
    "dqn.save_weights('d:\\\\RL-DQN-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
