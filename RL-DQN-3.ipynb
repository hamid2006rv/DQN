{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import  SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        p.connect(p.GUI)\n",
    "        p.setRealTimeSimulation(1)\n",
    "        p.resetDebugVisualizerCamera(cameraDistance=10, cameraYaw=0, cameraPitch=-40, cameraTargetPosition=[0.55,-0.35,0.2])\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(np.array([-1000]*13), np.array([1000]*13))\n",
    "        self.timestep = 1./240.\n",
    "        \n",
    "    def step(self, action):\n",
    "\n",
    "        if (action == 0):\n",
    "            self.speed = self.speed + 1\n",
    "        if (action == 1):\n",
    "            self.speed = self.speed - 1 \n",
    "        if (action == 2):\n",
    "            self.speed = self.speed  \n",
    "        if (action == 3):\n",
    "            self.steer = self.steer - 1 \n",
    "        if (action == 4):\n",
    "            self.steer = self.steer + 1\n",
    "        if (action == 5):\n",
    "            self.steer = self.steer \n",
    "            \n",
    "              \n",
    "        self.applyAction([self.speed,self.steer])\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        state = p.getLinkState(self.pid,0)[0]\n",
    "        if state[2] <= 0.5 or  state[2] >= 2 or abs(self.speed)>2 or abs(self.steer)>4:\n",
    "            reward = -100\n",
    "            done = True\n",
    "            \n",
    "        else :\n",
    "            reward = math.sqrt((self.origin[0]-state[0])**2+(self.origin[1]-state[1])**2)\n",
    "            #reward = 1\n",
    "            done = False\n",
    "        self.origin = state \n",
    "        \n",
    "        velocity = p.getBaseVelocity(self.pid)\n",
    "        observation = list(self.getObservation()) + list(velocity[0])+list(velocity[1])\n",
    "        \n",
    "        info = {'x':'','y':'','z':''}\n",
    "        #print(\"Step: \",self.stp)\n",
    "        #xx = time.time()\n",
    "        #print(\"Time: \",xx-self.tttt)\n",
    "        #self.tttt = xx\n",
    "        #print(\"Action: \",action)\n",
    "        #print(\"Reward: \",reward)\n",
    "        #self.stp +=1\n",
    "        return observation, reward, done, info\n",
    "            \n",
    "    def applyAction(self, motorCommands):\n",
    "        targetVelocity = motorCommands[0] * self.speedMultiplier\n",
    "        #print(\"targetVelocity\")\n",
    "        #print(targetVelocity)\n",
    "        steeringAngle = motorCommands[1] * self.steeringMultiplier\n",
    "        #print(\"steeringAngle\")\n",
    "        #print(steeringAngle)\n",
    "\n",
    "\n",
    "        for motor in self.motorizedwheels:\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    motor,\n",
    "                                    p.VELOCITY_CONTROL,\n",
    "                                    targetVelocity=targetVelocity,\n",
    "                                    force=self.maxForce)\n",
    "        for steer in self.steeringLinks:\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    steer,\n",
    "                                    p.POSITION_CONTROL,\n",
    "                                    targetPosition=steeringAngle)\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        #print(\"===========Reset=====\")\n",
    "        self.stp=0\n",
    "        self.tttt= time.time()\n",
    "        p.resetSimulation()\n",
    "\n",
    "        urdfRootPath = pybullet_data.getDataPath()\n",
    "        planeUid = p.loadURDF(os.path.join(urdfRootPath,\"plane.urdf\"), basePosition=[0,0,0])\n",
    "        self.pid = p.loadURDF(os.path.join(urdfRootPath, \"bicycle/bike.urdf\"),basePosition=[0,0,1])\n",
    "        self.origin = p.getLinkState(self.pid,0)[0]\n",
    "        p.setGravity(0,0,-10)\n",
    "        for wheel in range(p.getNumJoints(self.pid)):\n",
    "            p.setJointMotorControl2(self.pid,\n",
    "                                    wheel,\n",
    "                                    p.VELOCITY_CONTROL,\n",
    "                                    targetVelocity=0,\n",
    "                                    force=0)\n",
    "\n",
    "        self.steeringLinks = [0]\n",
    "        self.maxForce = 20\n",
    "        self.nMotors = 2\n",
    "        self.motorizedwheels = [1, 2]\n",
    "        self.speedMultiplier = 10.\n",
    "        self.steeringMultiplier = 0.5\n",
    "        \n",
    "        self.speed = 0 \n",
    "        self.steer = 0\n",
    "\n",
    "        velocity = p.getBaseVelocity(self.pid)\n",
    "        observation = list(self.getObservation()) + list(velocity[0])+list(velocity[1])\n",
    "        p.configureDebugVisualizer(p.COV_ENABLE_RENDERING,1)\n",
    "        return observation\n",
    "        \n",
    "    def getObservationDimension(self):\n",
    "        return len(self.getObservation())\n",
    "    \n",
    "    def getObservation(self):\n",
    "        observation = []\n",
    "        pos, orn = p.getBasePositionAndOrientation(self.pid)\n",
    "\n",
    "        observation.extend(list(pos))\n",
    "        observation.extend(list(orn))\n",
    "        return observation\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        view_matrix = p.computeViewMatrixFromYawPitchRoll(cameraTargetPosition=[0.7,0,0.05],\n",
    "                                                            distance=.7,\n",
    "                                                            yaw=90,\n",
    "                                                            pitch=-70,\n",
    "                                                            roll=0,\n",
    "                                                            upAxisIndex=2)\n",
    "        proj_matrix = p.computeProjectionMatrixFOV(fov=60,\n",
    "                                                     aspect=float(960) /720,\n",
    "                                                     nearVal=0.1,\n",
    "                                                     farVal=100.0)\n",
    "        (_, _, px, _, _) = p.getCameraImage(width=960,\n",
    "                                              height=720,\n",
    "                                              viewMatrix=view_matrix,\n",
    "                                              projectionMatrix=proj_matrix,\n",
    "                                              renderer=p.ER_BULLET_HARDWARE_OPENGL)\n",
    "\n",
    "        rgb_array = np.array(px, dtype=np.uint8)\n",
    "        rgb_array = np.reshape(rgb_array, (720,960, 4))\n",
    "\n",
    "        rgb_array = rgb_array[:, :, :3]\n",
    "        return rgb_array\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = BikeEnv()\n",
    "np.random.seed(123)\n",
    "env.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 102       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From C:\\Users\\SERVER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "10000/10000 [==============================] - 2608s 261ms/step - reward: -14.3862\n",
      "1460 episodes - episode_reward: -98.536 [-99.894, -89.600] - loss: 24.963 - mae: 74.602 - mean_q: -87.876\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 2554s 255ms/step - reward: -13.3317\n",
      "1363 episodes - episode_reward: -97.814 [-99.752, -87.104] - loss: 1.636 - mae: 79.021 - mean_q: -93.771\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 2491s 249ms/step - reward: -10.6539\n",
      "1120 episodes - episode_reward: -95.122 [-99.757, -85.895] - loss: 2.419 - mae: 77.598 - mean_q: -91.034\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 2479s 248ms/step - reward: -10.2347\n",
      "1082 episodes - episode_reward: -94.595 [-99.838, -86.323] - loss: 2.083 - mae: 77.294 - mean_q: -90.493\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 2478s 248ms/step - reward: -10.1112\n",
      "done, took 12609.794 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x168b3860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('d:\\\\RL-DQN-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 2439s 244ms/step - reward: -9.6455\n",
      "1030 episodes - episode_reward: -93.649 [-99.650, -80.895] - loss: 1.770 - mae: 76.491 - mean_q: -89.103\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 2425s 242ms/step - reward: -9.3636\n",
      "1004 episodes - episode_reward: -93.261 [-99.648, -83.088] - loss: 1.556 - mae: 76.134 - mean_q: -88.502\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 2416s 242ms/step - reward: -9.0403\n",
      "974 episodes - episode_reward: -92.824 [-99.612, -76.946] - loss: 1.375 - mae: 76.144 - mean_q: -88.313\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 2424s 242ms/step - reward: -8.8069\n",
      "952 episodes - episode_reward: -92.503 [-99.695, -72.955] - loss: 1.224 - mae: 76.065 - mean_q: -88.054\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 2403s 240ms/step - reward: -8.6307\n",
      "done, took 12108.207 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1eed4b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 150000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 2383s 238ms/step - reward: -8.3599\n",
      "909 episodes - episode_reward: -91.969 [-99.595, -79.060] - loss: 1.005 - mae: 75.927 - mean_q: -87.813\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 2404s 240ms/step - reward: -7.8826\n",
      "864 episodes - episode_reward: -91.241 [-99.559, -80.295] - loss: 1.041 - mae: 75.771 - mean_q: -87.354\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 2395s 240ms/step - reward: -7.6434\n",
      "841 episodes - episode_reward: -90.888 [-99.429, -79.651] - loss: 1.047 - mae: 75.480 - mean_q: -86.888\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 2396s 240ms/step - reward: -7.6360\n",
      "840 episodes - episode_reward: -90.897 [-99.332, -78.860] - loss: 1.087 - mae: 75.233 - mean_q: -86.599\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 2375s 238ms/step - reward: -7.6563\n",
      "843 episodes - episode_reward: -90.830 [-99.251, -74.918] - loss: 1.153 - mae: 75.075 - mean_q: -86.323\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 2372s 237ms/step - reward: -7.6528\n",
      "843 episodes - episode_reward: -90.776 [-99.751, -75.272] - loss: 1.154 - mae: 75.014 - mean_q: -86.126\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 2375s 237ms/step - reward: -7.6858\n",
      "846 episodes - episode_reward: -90.842 [-99.567, -72.372] - loss: 1.210 - mae: 75.077 - mean_q: -85.941\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 2368s 237ms/step - reward: -7.3962\n",
      "819 episodes - episode_reward: -90.307 [-99.717, -76.991] - loss: 1.155 - mae: 75.253 - mean_q: -85.939\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 2361s 236ms/step - reward: -7.1848\n",
      "799 episodes - episode_reward: -89.934 [-98.763, -71.551] - loss: 1.123 - mae: 75.314 - mean_q: -85.908\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 2358s 236ms/step - reward: -7.1089\n",
      "793 episodes - episode_reward: -89.637 [-99.514, -66.714] - loss: 1.158 - mae: 75.217 - mean_q: -85.777\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      "10000/10000 [==============================] - 2356s 236ms/step - reward: -6.9365\n",
      "778 episodes - episode_reward: -89.165 [-99.550, -65.023] - loss: 1.308 - mae: 74.958 - mean_q: -85.400\n",
      "\n",
      "Interval 12 (110000 steps performed)\n",
      "10000/10000 [==============================] - 2329s 233ms/step - reward: -6.0048\n",
      "695 episodes - episode_reward: -86.388 [-99.558, -52.138] - loss: 1.770 - mae: 74.490 - mean_q: -84.141\n",
      "\n",
      "Interval 13 (120000 steps performed)\n",
      "10000/10000 [==============================] - 2322s 232ms/step - reward: -5.5165\n",
      "650 episodes - episode_reward: -84.871 [-99.558, -52.138] - loss: 2.683 - mae: 73.783 - mean_q: -82.123\n",
      "\n",
      "Interval 14 (130000 steps performed)\n",
      "10000/10000 [==============================] - 2305s 230ms/step - reward: -4.9859\n",
      "601 episodes - episode_reward: -82.958 [-99.719, -52.174] - loss: 3.226 - mae: 73.332 - mean_q: -80.413\n",
      "\n",
      "Interval 15 (140000 steps performed)\n",
      "10000/10000 [==============================] - 2293s 229ms/step - reward: -4.4701\n",
      "done, took 35393.730 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1eed4dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=150000, visualize=False, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
